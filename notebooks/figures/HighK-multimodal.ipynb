{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "# Third-party\n",
    "from astropy.io import fits\n",
    "from astropy.stats import median_absolute_deviation\n",
    "from astropy.table import Table, join\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sqlalchemy import func\n",
    "import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from thejoker import JokerSamples\n",
    "\n",
    "from twoface.config import TWOFACE_CACHE_PATH\n",
    "from twoface.samples_analysis import unimodal_P, MAP_sample\n",
    "from twoface.db import (db_connect, AllStar, AllVisit, AllVisitToAllStar, NessRG,\n",
    "                        StarResult, Status, JokerRun)\n",
    "from twoface.plot import plot_two_panel, plot_phase_fold, _RV_LBL\n",
    "from twoface.mass import get_m2_min, mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session, _ = db_connect(path.join(TWOFACE_CACHE_PATH, 'apogee.sqlite'))\n",
    "session = Session()\n",
    "\n",
    "plot_path = '../../paper/1-catalog/figures/'\n",
    "table_path = '../../paper/1-catalog/tables/'\n",
    "\n",
    "samples_file = path.join(TWOFACE_CACHE_PATH, 'apogee-jitter.hdf5')\n",
    "mcmc_samples_file = path.join(TWOFACE_CACHE_PATH, 'apogee-jitter-mcmc.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = session.query(JokerRun).limit(1).one()\n",
    "joker_pars = run.get_joker_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_K_stars = session.query(AllStar).join(StarResult).filter(StarResult.status_id.in_([1, 4]))\\\n",
    "                      .filter(StarResult.high_K).all()\n",
    "len(high_K_stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_n_modal(data, samples, n_clusters=2):\n",
    "    clf = KMeans(n_clusters=n_clusters)\n",
    "    \n",
    "    ecc = samples['e'].value\n",
    "    lnP = np.log(samples['P'].value).reshape(-1, 1)\n",
    "    y = clf.fit_predict(lnP)\n",
    "\n",
    "    data = star.apogeervdata()\n",
    "    \n",
    "    unimodals = []\n",
    "    for j in np.unique(y):\n",
    "        unimodals.append(unimodal_P(samples[y==j], data))\n",
    "        \n",
    "    return all(unimodals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bimodal = []\n",
    "nsamples = []\n",
    "\n",
    "n = 0\n",
    "with h5py.File(samples_file, 'r') as f:\n",
    "    for star in tqdm.tqdm(high_K_stars):\n",
    "        samples = JokerSamples.from_hdf5(f[star.apogee_id])\n",
    "        data = star.apogeervdata()\n",
    "        \n",
    "        if len(samples) > 1:\n",
    "            bimodal.append(is_n_modal(data, samples, n_clusters=2))\n",
    "            \n",
    "        else:\n",
    "            bimodal.append(False)\n",
    "        \n",
    "        nsamples.append(len(samples))\n",
    "\n",
    "nsamples = np.array(nsamples)\n",
    "bimodal = np.array(bimodal)\n",
    "bimodal.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these only have a few samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(nsamples[bimodal], bins='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Make paper figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog = Table.read(path.join(table_path, 'high'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File(samples_file, 'r') as f:\n",
    "#     for star in tqdm.tqdm(np.array(high_K_stars)[bimodal][:10]):\n",
    "#         samples = JokerSamples.from_hdf5(f[star.apogee_id])\n",
    "#         data = star.apogeervdata()\n",
    "        \n",
    "#         _ = plot_two_panel(data, samples, \n",
    "#                            plot_data_orbits_kw=dict(highlight_P_extrema=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(36)\n",
    "\n",
    "rc = {\n",
    "    'axes.labelsize': 18,\n",
    "    'xtick.labelsize': 14,\n",
    "    'ytick.labelsize': 14\n",
    "}\n",
    "    \n",
    "rand_subset = np.random.choice(np.array(high_K_stars)[bimodal], size=4, \n",
    "                               replace=False)\n",
    "    \n",
    "with mpl.rc_context(rc):\n",
    "    gs = GridSpec(4, 3)\n",
    "    fig = plt.figure(figsize=(8., 9.5))\n",
    "    for j, star in enumerate(rand_subset):\n",
    "        ax1 = fig.add_subplot(gs[j, :2])\n",
    "        ax2 = fig.add_subplot(gs[j, 2])\n",
    "\n",
    "        if j == 0:\n",
    "            ax1.set_title('Mildly multi-modal, high-$K$ stars', fontsize=20)\n",
    "\n",
    "        data = star.apogeervdata()\n",
    "\n",
    "        with h5py.File(samples_file, 'r') as f:\n",
    "            samples = JokerSamples.from_hdf5(f[star.apogee_id])\n",
    "\n",
    "        fig = plot_two_panel(data, samples, axes=[ax1, ax2], tight=False,\n",
    "                             plot_data_orbits_kw=dict(n_times=16384, \n",
    "                                                      n_orbits=128,\n",
    "                                                      highlight_P_extrema=False,\n",
    "                                                      xlim_choice='data',\n",
    "                                                      relative_to_t0=True,\n",
    "                                                      plot_kwargs=dict(linewidth=0.2,\n",
    "                                                                       rasterized=True)))\n",
    "\n",
    "        xlim = ax1.get_xlim()\n",
    "        ylim = ax1.get_ylim()\n",
    "\n",
    "        ax1.text(xlim[0] + (xlim[1]-xlim[0])/20,\n",
    "                 ylim[1] - (ylim[1]-ylim[0])/20,\n",
    "                 star.apogee_id, fontsize=15, va='top', ha='left')\n",
    "\n",
    "        ax1.set_xlabel('')\n",
    "        ax2.set_xlabel('')\n",
    "\n",
    "    ax1.set_xlabel(r'${\\rm BMJD} - t_0$ [day]')\n",
    "    ax2.set_xlabel('period, $P$ [day]')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(left=0.125, right=0.95, hspace=0.2, wspace=0.4)\n",
    "    \n",
    "    fig.savefig(path.join(plot_path, 'highK-multimodal.pdf'), dpi=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stars with samples that have small dispersion, or PTP lnP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "with h5py.File(samples_file, 'r') as f:\n",
    "    for star in tqdm.tqdm(high_K_stars):\n",
    "        lnP = np.log(f[star.apogee_id]['P'][:])\n",
    "        stats.append([np.ptp(lnP), np.std(lnP)])\n",
    "stats = np.array(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "ax.scatter(stats[:, 0], 3*stats[:, 1], alpha=0.25, linewidth=0)\n",
    "ax.set_xlim(-0.02, 10.5)\n",
    "ax.set_ylim(-0.02, 10.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((stats[:, 0] < 3) & bimodal).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# star = np.array(high_K_stars)[(stats[:, 0] > 8) & (stats[:, 1] < 2)][0]\n",
    "# star = np.array(high_K_stars)[(stats[:, 0] < 2) & (stats[:, 1] < 2)][0]\n",
    "# star = np.array(high_K_stars)[(stats[:, 0] > 2) & (stats[:, 0] < 4) & (stats[:, 1] < 2)][4]\n",
    "\n",
    "data = star.apogeervdata()\n",
    "with h5py.File(samples_file, 'r') as f:\n",
    "    samples = JokerSamples.from_hdf5(f[star.apogee_id])\n",
    "    \n",
    "_ = plot_two_panel(data, samples, plot_data_orbits_kw=dict(highlight_P_extrema=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce catalog table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimodal_stars = np.array(high_K_stars)[unimodal_mask]\n",
    "unimodal_converged = converged_mcmc[unimodal_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = dict()\n",
    "rows['APOGEE_ID'] = []\n",
    "for k in JokerSamples._valid_keys:\n",
    "    rows[k] = []\n",
    "    rows[k + '_err'] = []\n",
    "rows['t0'] = []\n",
    "rows['emcee_converged'] = []\n",
    "rows['Gelman-Rubin'] = []\n",
    "\n",
    "with h5py.File(mcmc_samples_file, 'r') as mcmc_f, h5py.File(samples_file, 'r') as joker_f:\n",
    "    for i, star in tqdm.tqdm(enumerate(unimodal_stars)):\n",
    "        data = star.apogeervdata()\n",
    "        if star.apogee_id in mcmc_f:\n",
    "            samples = JokerSamples.from_hdf5(mcmc_f[star.apogee_id])\n",
    "            R = mcmc_f[star.apogee_id]['chain-stats/gelman_rubin'][:]\n",
    "        else:\n",
    "            samples = JokerSamples.from_hdf5(joker_f[star.apogee_id])\n",
    "            R = np.full(7, np.nan)\n",
    "        \n",
    "        rows['APOGEE_ID'].append(star.apogee_id)\n",
    "        MAP = MAP_sample(data, samples, joker_pars)\n",
    "        for k in samples.keys():\n",
    "            rows[k].append(MAP[k])\n",
    "            rows[k+'_err'].append(1.5 * median_absolute_deviation(samples[k]))\n",
    "            \n",
    "        rows['t0'].append(data.t0.tcb.mjd)\n",
    "        rows['emcee_converged'].append(unimodal_converged[i])\n",
    "        rows['Gelman-Rubin'].append(R)\n",
    "        \n",
    "for k in rows:\n",
    "    if hasattr(rows[k][0], 'unit'):\n",
    "        rows[k] = u.Quantity(rows[k])\n",
    "        \n",
    "rows['t0'] = Time(rows['t0'], format='mjd', scale='tcb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = Table(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Ness masses to table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ness_tbl = Table.read('../../data/NessRG.fits')\n",
    "ness_tbl.rename_column('2MASS', 'APOGEE_ID')\n",
    "ness_tbl = ness_tbl[np.isin(ness_tbl['APOGEE_ID'], tbl['APOGEE_ID'])]\n",
    "\n",
    "# trim the duplicates...\n",
    "_, unq_idx = np.unique(ness_tbl['APOGEE_ID'], return_index=True)\n",
    "ness_tbl = ness_tbl[unq_idx]\n",
    "\n",
    "tbl_with_ness = join(tbl, ness_tbl, keys='APOGEE_ID', join_type='outer')\n",
    "assert len(tbl_with_ness) == len(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute m2_min using Ness mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.RandomState(seed=42)\n",
    "N = rnd.normal\n",
    "\n",
    "mass_ratio = np.full(len(tbl_with_ness), np.nan)\n",
    "mass_ratio_err = np.full(len(tbl_with_ness), np.nan)\n",
    "m1 = np.full(len(tbl_with_ness), np.nan) * u.Msun\n",
    "m1_err = np.full(len(tbl_with_ness), np.nan) * u.Msun\n",
    "m2_min = np.full(len(tbl_with_ness), np.nan) * u.Msun\n",
    "m2_min_err = np.full(len(tbl_with_ness), np.nan) * u.Msun\n",
    "\n",
    "n_samples = 1024\n",
    "for i, row in tqdm.tqdm(enumerate(tbl_with_ness)):\n",
    "    if tbl_with_ness['lnM'].mask[i]:\n",
    "        continue\n",
    "        \n",
    "    m1_samples = np.exp(N(row['lnM'], row['e_logM'], size=n_samples)) * u.Msun\n",
    "    mass_func = mf(P=N(row['P'], row['P_err'], n_samples) * tbl_with_ness['P'].unit, \n",
    "                   K=N(row['K'], row['K_err'], n_samples) * tbl_with_ness['K'].unit,\n",
    "                   e=N(row['e'], row['e_err'], n_samples))\n",
    "    m2_mins = get_m2_min(m1_samples, mass_func)\n",
    "\n",
    "    med_m1 = np.median(m1_samples)\n",
    "    med_m2 = np.median(m2_mins)\n",
    "    \n",
    "    m1[i] = med_m1\n",
    "    m1_err[i] = 1.5*median_absolute_deviation(m1_samples)\n",
    "    m2_min[i] = med_m2\n",
    "    m2_min_err[i] = 1.5*median_absolute_deviation(m2_mins)\n",
    "    mass_ratio[i] = (med_m2 / med_m1).decompose().value\n",
    "    mass_ratio_err[i] = 1.5*median_absolute_deviation(m2_mins / m1_samples).decompose().value\n",
    "    \n",
    "tbl_with_ness['M1'] = m1\n",
    "tbl_with_ness['M1_err'] = m1_err\n",
    "tbl_with_ness['M2_min'] = m2_min\n",
    "tbl_with_ness['M2_min_err'] = m2_min_err\n",
    "\n",
    "tbl_with_ness['M1'].mask = np.isnan(tbl_with_ness['M1'])\n",
    "tbl_with_ness['M1_err'].mask = np.isnan(tbl_with_ness['M1'])\n",
    "tbl_with_ness['M2_min'].mask = np.isnan(tbl_with_ness['M1'])\n",
    "tbl_with_ness['M2_min_err'].mask = np.isnan(tbl_with_ness['M1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we load the APOGEE AllStar table to join the APOGEE data with our orbits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allstar_tbl = fits.getdata('/Users/adrian/data/APOGEE_DR14/allStar-l31c.2.fits')\n",
    "allstar_tbl = allstar_tbl[np.isin(allstar_tbl['APOGEE_ID'], tbl['APOGEE_ID'])]\n",
    "\n",
    "# trim the duplicates...\n",
    "_, unq_idx = np.unique(allstar_tbl['APOGEE_ID'], return_index=True)\n",
    "allstar_tbl = allstar_tbl[unq_idx]\n",
    "assert len(allstar_tbl) == len(tbl)\n",
    "\n",
    "allstar_tbl = Table(allstar_tbl)\n",
    "allstar_tbl.rename_column('K', 'KS')\n",
    "allstar_tbl.rename_column('K_ERR', 'KS_ERR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog = join(tbl_with_ness, allstar_tbl, keys='APOGEE_ID')\n",
    "full_catalog[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, add a binary flag \"DR14RC\" if in DR14 RC catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = Table.read('/Users/adrian/data/APOGEE_DR14/apogee-rc-DR14.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog['DR14RC'] = np.isin(full_catalog['APOGEE_ID'], rc['APOGEE_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: describe in README with data to use `Table.read('', astropy_native=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog['M1'][full_catalog['M1'].mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog.write(path.join(table_path, 'high-K-unimodal.fits'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in full_catalog.colnames[:18] + full_catalog.colnames[33:37]:\n",
    "    c1 = '\\\\texttt{{{0}}}'.format(name.replace('_', '\\\\_'))\n",
    "    try:\n",
    "        c2 = '{0:latex_inline}'.format(full_catalog[name].unit)\n",
    "    except TypeError:\n",
    "        c2 = ''\n",
    "    except AttributeError:\n",
    "        c2 = ''\n",
    "    \n",
    "    if len(c1) < 26:\n",
    "        c1 = c1 + ' '*(26 - len(c1))\n",
    "        \n",
    "    if len(c2) < 24:\n",
    "        c2 = c2 + ' '*(24 - len(c2))\n",
    "        \n",
    "    print('{0} & {1} & <description> \\\\\\\\'.format(c1, c2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emcee_converged = full_catalog[full_catalog['emcee_converged']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_path = '../../plots/emcee_converged'\n",
    "os.makedirs(_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(mcmc_samples_file, 'r') as mcmc_f, h5py.File(samples_file, 'r') as f:\n",
    "    for row in emcee_converged:\n",
    "        star = AllStar.get_apogee_id(session, row['APOGEE_ID'])\n",
    "        data = star.apogeervdata()\n",
    "    \n",
    "        if star.apogee_id in mcmc_f:\n",
    "            samples = JokerSamples.from_hdf5(mcmc_f[star.apogee_id])\n",
    "            print('mcmc')\n",
    "        else:\n",
    "            samples = JokerSamples.from_hdf5(f[star.apogee_id])\n",
    "            print('thejoker')\n",
    "            \n",
    "        samples.t0 = data.t0\n",
    "        \n",
    "        fig = plot_two_panel(data, samples, \n",
    "                             plot_data_orbits_kw=dict(n_times=16384,                \n",
    "                                                      highlight_P_extrema=False))\n",
    "        fig.axes[0].set_title(star.apogee_id)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(path.join(_path, '{0}.png'.format(star.apogee_id)), dpi=200)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By-eye vetting: these ones are suspicious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspicious_ids = ['2M05224382+4300425',\n",
    "                  '2M08505498+1156503',\n",
    "                  '2M10264342+1340172',\n",
    "                  '2M10513288-0250550',\n",
    "                  '2M14574438+2106271',\n",
    "                  '2M16131259+5043080',\n",
    "                  '2M17121495+3211467',\n",
    "                  '2M17212080+6003296',\n",
    "                  '2M18571262-0328064',\n",
    "                  '2M21260907+1100178',\n",
    "                  '2M21374395+4304268']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derp = emcee_converged[~np.isin(emcee_converged['APOGEE_ID'], suspicious_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "\n",
    "ax.errorbar(derp['P'], derp['LOGG'],\n",
    "            xerr=derp['P_err'], yerr=derp['LOGG_ERR'],\n",
    "            marker='o', linestyle='none', alpha=0.8)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylim(4., 0)\n",
    "ax.set_xlabel('P')\n",
    "ax.set_ylabel('logg')\n",
    "\n",
    "# -----\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "\n",
    "ax.errorbar(derp['P'], derp['e'],\n",
    "            xerr=derp['P_err'], yerr=derp['e_err'],\n",
    "            marker='o', linestyle='none', alpha=0.8)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel('P')\n",
    "ax.set_ylabel('e')\n",
    "\n",
    "# -----\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.errorbar(derp['M1'], derp['M2_min']/derp['M1'],\n",
    "            xerr=derp['M1_err'], yerr=np.sqrt(derp['M1_err']**2+derp['M2_min_err']**2),\n",
    "            marker='o', linestyle='none', alpha=0.8)\n",
    "ax.set_xlabel('M1')\n",
    "ax.set_ylabel('M2/M1')\n",
    "\n",
    "ax = axes[1]\n",
    "mass_ratio = derp['M2_min']/derp['M1']\n",
    "ax.hist(mass_ratio[np.isfinite(mass_ratio)], bins='auto')\n",
    "ax.set_xlabel('M2/M1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(mcmc_samples_file, 'r') as mcmc_f, h5py.File(samples_file, 'r') as f:\n",
    "    for row in derp[rc_mask & (derp['P'] < 20)]:\n",
    "        star = AllStar.get_apogee_id(session, row['APOGEE_ID'])\n",
    "        data = star.apogeervdata()\n",
    "    \n",
    "        if star.apogee_id in mcmc_f:\n",
    "            samples = JokerSamples.from_hdf5(mcmc_f[star.apogee_id])\n",
    "            print('mcmc')\n",
    "        else:\n",
    "            samples = JokerSamples.from_hdf5(f[star.apogee_id])\n",
    "            print('thejoker')\n",
    "            \n",
    "        samples.t0 = data.t0\n",
    "        \n",
    "        fig = plot_two_panel(data, samples, \n",
    "                             plot_data_orbits_kw=dict(n_times=16384,                \n",
    "                                                      highlight_P_extrema=False))\n",
    "        fig.axes[0].set_title('P = {0:.2f}'.format(samples['P'][0]))\n",
    "        fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derp[rc_mask & (derp['P'] < 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:twoface]",
   "language": "python",
   "name": "conda-env-twoface-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}