{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "# Third-party\n",
    "from astropy.io import fits\n",
    "from astropy.stats import median_absolute_deviation\n",
    "from astropy.table import Table, join\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sqlalchemy import func\n",
    "import tqdm\n",
    "\n",
    "from thejoker import JokerSamples\n",
    "\n",
    "from twoface.config import TWOFACE_CACHE_PATH\n",
    "from twoface.samples_analysis import unimodal_P\n",
    "from twoface.db import (db_connect, AllStar, AllVisit, AllVisitToAllStar, NessRG,\n",
    "                        StarResult, Status, JokerRun, initialize_db)\n",
    "from twoface.plot import plot_two_panel, plot_phase_fold, _RV_LBL\n",
    "from twoface.mass import get_m2_min, mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session, _ = db_connect(path.join(TWOFACE_CACHE_PATH, 'apogee.sqlite'))\n",
    "session = Session()\n",
    "\n",
    "samples_file = path.join(TWOFACE_CACHE_PATH, 'apogee-jitter.hdf5')\n",
    "mcmc_samples_file = path.join(TWOFACE_CACHE_PATH, 'apogee-jitter-mcmc.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_K_stars = session.query(AllStar).join(StarResult).filter(StarResult.status_id>0).filter(StarResult.high_K).all()\n",
    "len(high_K_stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all high-K stars, classify as unimodal or not based on TheJoker samples. Then do same for MCMC samples, AND the selections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimodal_thejoker = []\n",
    "with h5py.File(samples_file, 'r') as f:\n",
    "    for star in tqdm.tqdm(high_K_stars):\n",
    "        samples = JokerSamples.from_hdf5(f[star.apogee_id])\n",
    "\n",
    "        data = star.apogeervdata()\n",
    "        unimodal_thejoker.append(unimodal_P(samples, data))\n",
    "\n",
    "unimodal_thejoker = np.array(unimodal_thejoker)\n",
    "unimodal_thejoker.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimodal_mcmc = []\n",
    "converged_mcmc = []\n",
    "with h5py.File(mcmc_samples_file, 'r') as f:\n",
    "    for star in tqdm.tqdm(high_K_stars):\n",
    "        if star.apogee_id not in f: \n",
    "            unimodal_mcmc.append(False)\n",
    "            converged_mcmc.append(False)\n",
    "            continue\n",
    "        \n",
    "        R = f[star.apogee_id]['chain-stats/gelman_rubin'][:]\n",
    "        converged_mcmc.append(np.mean(R) < 1.1)\n",
    "        \n",
    "        samples = JokerSamples.from_hdf5(f[star.apogee_id])\n",
    "\n",
    "        data = star.apogeervdata()\n",
    "        unimodal_mcmc.append(unimodal_P(samples, data))\n",
    "        \n",
    "unimodal_mcmc = np.array(unimodal_mcmc)\n",
    "converged_mcmc = np.array(converged_mcmc)\n",
    "unimodal_mcmc.sum(), converged_mcmc.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimodal_mask = unimodal_thejoker | unimodal_mcmc\n",
    "unimodal_converged_mask = unimodal_thejoker & (unimodal_mcmc & converged_mcmc)\n",
    "unimodal_converged_idx = np.where(unimodal_converged_mask)[0]\n",
    "unimodal_mask.sum(), unimodal_converged_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(123)\n",
    "np.random.seed(1123)\n",
    "\n",
    "rand_subset = np.random.choice(unimodal_converged_idx, size=8, \n",
    "                               replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(12, 15), sharex=True)\n",
    "\n",
    "for i, idx in enumerate(rand_subset):\n",
    "    ax = axes.flat[i]\n",
    "    \n",
    "    star = high_K_stars[idx]\n",
    "    data = star.apogeervdata()\n",
    "    \n",
    "    if unimodal_mcmc[idx] & converged_mcmc[idx]:\n",
    "        fn = mcmc_samples_file\n",
    "        print('mcmc')\n",
    "    else:\n",
    "        fn = samples_file\n",
    "        print('thejoker')\n",
    "        \n",
    "    with h5py.File(fn, 'r') as f:\n",
    "        samples = JokerSamples.from_hdf5(f[star.apogee_id])\n",
    "        \n",
    "    samples.t0 = data.t0\n",
    "        \n",
    "    fig = plot_phase_fold(data, samples[5], ax=ax, \n",
    "                          jitter_errorbar=True, label=False)\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = (data.rv.value.min(), data.rv.value.max())\n",
    "    yspan = ylim[1]-ylim[0]\n",
    "    ylim = ax.set_ylim(ylim[0]-0.35*yspan, ylim[1]+0.35*yspan)\n",
    "    \n",
    "    text = ('{0},    '.format(star.apogee_id) + \n",
    "            '$P = {0.value:.2f}$ {0.unit:latex},    '.format(np.mean(samples['P'])) + \n",
    "            '$e = {0:.2f}$'.format(np.mean(samples['e'])))\n",
    "    ax.text(xlim[0] + (xlim[1]-xlim[0])/20,\n",
    "            ylim[1] - (ylim[1]-ylim[0])/20,\n",
    "            text, fontsize=15, va='top', ha='left')\n",
    "    # _ = plot_two_panel(data, samples)\n",
    "\n",
    "ax.set_xlim(-0.02, 1.02)\n",
    "    \n",
    "for i in [0,1]:\n",
    "    axes[-1, i].set_xlabel(r'phase, $\\frac{M-M_0}{2\\pi}$')\n",
    "    \n",
    "for i in range(4):\n",
    "    axes[i, 0].set_ylabel(_RV_LBL.format(u.km/u.s))\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.savefig(path.join(plot_path, 'highK-unimodal.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce catalog table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimodal_stars = np.array(high_K_stars)[unimodal_mask]\n",
    "unimodal_converged = converged_mcmc[unimodal_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = dict()\n",
    "rows['APOGEE_ID'] = []\n",
    "for k in JokerSamples._valid_keys:\n",
    "    rows[k] = []\n",
    "    rows[k + '_err'] = []\n",
    "rows['t0'] = []\n",
    "rows['emcee_converged'] = []\n",
    "rows['Gelman-Rubin'] = []\n",
    "\n",
    "with h5py.File(mcmc_samples_file, 'r') as mcmc_f, h5py.File(samples_file, 'r') as joker_f:\n",
    "    for i, star in tqdm.tqdm(enumerate(unimodal_stars)):\n",
    "        data = star.apogeervdata()\n",
    "        if star.apogee_id in mcmc_f:\n",
    "            samples = JokerSamples.from_hdf5(mcmc_f[star.apogee_id])\n",
    "            R = mcmc_f[star.apogee_id]['chain-stats/gelman_rubin'][:]\n",
    "        else:\n",
    "            samples = JokerSamples.from_hdf5(joker_f[star.apogee_id])\n",
    "            R = np.full(7, np.nan)\n",
    "        \n",
    "        rows['APOGEE_ID'].append(star.apogee_id)\n",
    "        for k in samples.keys():\n",
    "            rows[k].append(np.median(samples[k]))\n",
    "            rows[k+'_err'].append(1.5 * median_absolute_deviation(samples[k]))\n",
    "            \n",
    "        rows['t0'].append(data.t0.tcb.mjd)\n",
    "        rows['emcee_converged'].append(unimodal_converged[i])\n",
    "        rows['Gelman-Rubin'].append(R)\n",
    "        \n",
    "for k in rows:\n",
    "    if hasattr(rows[k][0], 'unit'):\n",
    "        rows[k] = u.Quantity(rows[k])\n",
    "        \n",
    "rows['t0'] = Time(rows['t0'], format='mjd', scale='tcb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = Table(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Ness masses to table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ness_tbl = Table.read('../../data/NessRG.fits')\n",
    "ness_tbl.rename_column('2MASS', 'APOGEE_ID')\n",
    "ness_tbl = ness_tbl[np.isin(ness_tbl['APOGEE_ID'], tbl['APOGEE_ID'])]\n",
    "\n",
    "# trim the duplicates...\n",
    "_, unq_idx = np.unique(ness_tbl['APOGEE_ID'], return_index=True)\n",
    "ness_tbl = ness_tbl[unq_idx]\n",
    "\n",
    "tbl_with_ness = join(tbl, ness_tbl, keys='APOGEE_ID', join_type='outer')\n",
    "assert len(tbl_with_ness) == len(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute m2_min using Ness mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.RandomState(seed=42)\n",
    "N = rnd.normal\n",
    "\n",
    "mass_ratio = np.full(len(tbl_with_ness), np.nan)\n",
    "mass_ratio_err = np.full(len(tbl_with_ness), np.nan)\n",
    "m1 = np.full(len(tbl_with_ness), np.nan) * u.Msun\n",
    "m1_err = np.full(len(tbl_with_ness), np.nan) * u.Msun\n",
    "m2_min = np.full(len(tbl_with_ness), np.nan) * u.Msun\n",
    "m2_min_err = np.full(len(tbl_with_ness), np.nan) * u.Msun\n",
    "\n",
    "n_samples = 1024\n",
    "for i, row in tqdm.tqdm(enumerate(tbl_with_ness)):\n",
    "    if tbl_with_ness['lnM'].mask[i]:\n",
    "        continue\n",
    "        \n",
    "    m1_samples = np.exp(N(row['lnM'], row['e_logM'], size=n_samples)) * u.Msun\n",
    "    mass_func = mf(P=N(row['P'], row['P_err'], n_samples) * tbl_with_ness['P'].unit, \n",
    "                   K=N(row['K'], row['K_err'], n_samples) * tbl_with_ness['K'].unit,\n",
    "                   e=N(row['e'], row['e_err'], n_samples))\n",
    "    m2_mins = get_m2_min(m1_samples, mass_func)\n",
    "\n",
    "    med_m1 = np.median(m1_samples)\n",
    "    med_m2 = np.median(m2_mins)\n",
    "    \n",
    "    m1[i] = med_m1\n",
    "    m1_err[i] = 1.5*median_absolute_deviation(m1_samples)\n",
    "    m2_min[i] = med_m2\n",
    "    m2_min_err[i] = 1.5*median_absolute_deviation(m2_mins)\n",
    "    mass_ratio[i] = (med_m2 / med_m1).decompose().value\n",
    "    mass_ratio_err[i] = 1.5*median_absolute_deviation(m2_mins / m1_samples).decompose().value\n",
    "    \n",
    "tbl_with_ness['M1'] = m1\n",
    "tbl_with_ness['M1_err'] = m1_err\n",
    "tbl_with_ness['M2_min'] = m1\n",
    "tbl_with_ness['M2_min_err'] = m1_err\n",
    "\n",
    "tbl_with_ness['M1'].mask = np.isnan(tbl_with_ness['M1'])\n",
    "tbl_with_ness['M1_err'].mask = np.isnan(tbl_with_ness['M1'])\n",
    "tbl_with_ness['M2_min'].mask = np.isnan(tbl_with_ness['M1'])\n",
    "tbl_with_ness['M2_min_err'].mask = np.isnan(tbl_with_ness['M1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we load the APOGEE AllStar table to join the APOGEE data with our orbits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allstar_tbl = fits.getdata('/Users/adrian/data/APOGEE_DR14/allStar-l31c.2.fits')\n",
    "allstar_tbl = allstar_tbl[np.isin(allstar_tbl['APOGEE_ID'], tbl['APOGEE_ID'])]\n",
    "\n",
    "# trim the duplicates...\n",
    "_, unq_idx = np.unique(allstar_tbl['APOGEE_ID'], return_index=True)\n",
    "allstar_tbl = allstar_tbl[unq_idx]\n",
    "assert len(allstar_tbl) == len(tbl)\n",
    "\n",
    "allstar_tbl = Table(allstar_tbl)\n",
    "allstar_tbl.rename_column('K', 'KS')\n",
    "allstar_tbl.rename_column('K_ERR', 'KS_ERR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog = join(tbl_with_ness, allstar_tbl, keys='APOGEE_ID')\n",
    "full_catalog[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: describe in README with data to use `Table.read('', astropy_native=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog.write('../../data/products/high-K-unimodal.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:twoface]",
   "language": "python",
   "name": "conda-env-twoface-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}