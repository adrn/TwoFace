{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.constants import G\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('apw-notebook')\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "from sqlalchemy import func\n",
    "from scipy.optimize import root\n",
    "\n",
    "from twoface.config import TWOFACE_CACHE_PATH\n",
    "from twoface.db import (db_connect, AllStar, AllVisit, AllVisitToAllStar, RedClump,\n",
    "                        StarResult, Status, JokerRun, initialize_db)\n",
    "\n",
    "from thejoker import JokerParams, TheJoker, JokerSamples\n",
    "from twoface.sample_prior import make_prior_cache\n",
    "from twoface.io import load_samples\n",
    "from twoface.plot import plot_data_orbits\n",
    "from twobody.celestial import RVOrbit, VelocityTrend1\n",
    "\n",
    "from scipy.misc import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TWOFACE_CACHE_PATH = path.abspath('../cache/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Session, _ = db_connect(path.join(TWOFACE_CACHE_PATH, 'apogee.sqlite'))\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the run parameters:\n",
    "run = session.query(JokerRun).filter(JokerRun.name == 'apogee-jitter').one()\n",
    "\n",
    "# load the posterior samples:\n",
    "samples_file = path.join(TWOFACE_CACHE_PATH, '{0}.hdf5'.format(run.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_normal(x, mu, std):\n",
    "    return -0.5*( ((x-mu) / std)**2 + np.log(2*np.pi*std**2))\n",
    "\n",
    "# test against (slower) scipy implementation:\n",
    "from scipy.stats import norm\n",
    "derp = np.random.uniform(-2, 2, size=100)\n",
    "pars = np.random.uniform(1E-3, 10, size=2)\n",
    "assert np.allclose(norm.logpdf(derp, loc=pars[0], scale=pars[1]),\n",
    "                   ln_normal(derp, *pars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This is just a sanity check that newly generated prior samples look like we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jitter_kwargs = dict(jitter=(float(run.jitter_mean),\n",
    "                             float(run.jitter_stddev)),\n",
    "                     jitter_unit=u.Unit(run.jitter_unit))\n",
    "print(jitter_kwargs)\n",
    "\n",
    "params = JokerParams(P_min=8*u.day, P_max=32768*u.day, anomaly_tol=1E-11,\n",
    "                     **jitter_kwargs)\n",
    "\n",
    "joker = TheJoker(params)\n",
    "\n",
    "make_prior_cache('/tmp/jitter.hdf5', joker, 100000, max_batch_size=10000)\n",
    "\n",
    "with h5py.File('/tmp/jitter.hdf5') as f:\n",
    "    prior = np.array(f['samples'])\n",
    "    \n",
    "    # jitter is saved in km/s\n",
    "    s = 1000 * prior[:,-1] \n",
    "    \n",
    "plt.hist(np.log(s**2), bins=np.linspace(-8, 18, 32));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks OK to me..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data by getting particular stars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The aspcapflag bitmask removes STAR_WARN\n",
    "# The starflag bitmask removes SUSPECT_BROAD_LINES \n",
    "stars = session.query(AllStar).join(StarResult, JokerRun, Status)\\\n",
    "                              .filter(Status.id > 0)\\\n",
    "                              .filter(JokerRun.name == 'apogee-jitter')\\\n",
    "                              .filter(AllStar.nvisits > 7)\\\n",
    "                              .filter(AllStar.aspcapflag.op('&')(2**7) == 0)\\\n",
    "                              .filter(AllStar.starflag.op('&')(2**17) == 0)\\\n",
    "                              .all()\n",
    "#                              .limit(1024).all()\n",
    "print(len(stars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_n = []\n",
    "apogee_ids = []\n",
    "with h5py.File(samples_file) as f:\n",
    "    # Values that aren't filled get set to nan\n",
    "    N = len(stars)\n",
    "    y_nk = np.full((N, 128), np.nan)\n",
    "    \n",
    "    for n, key in enumerate([s.apogee_id for s in stars]):\n",
    "        K = len(f[key]['jitter'])\n",
    "        \n",
    "        s = f[key]['jitter'][:] * 1000. # km/s to m/s\n",
    "        y_nk[n,:K] = np.log(s**2)\n",
    "        K_n.append(K)\n",
    "        apogee_ids.append(key)\n",
    "\n",
    "K_n = np.array(K_n)\n",
    "apogee_ids = np.array(apogee_ids)\n",
    "\n",
    "# for nulling out the probability for non-existing samples\n",
    "mask = np.zeros_like(y_nk)\n",
    "mask[y_nk == 9999.] = -np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data by getting a random batch of some size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_n = []\n",
    "# apogee_ids = []\n",
    "# with h5py.File(samples_file) as f:\n",
    "#     # Only load 10000 stars for now\n",
    "#     N = 2000\n",
    "#     # N = len(f.keys())\n",
    "    \n",
    "#     # Values that aren't filled get set to nan\n",
    "#     y_nk = np.full((N, 128), np.nan)\n",
    "    \n",
    "#     for n,key in enumerate(f):\n",
    "#         K = len(f[key]['jitter'])\n",
    "        \n",
    "#         s = f[key]['jitter'][:] * 1000. # km/s to m/s\n",
    "#         y_nk[n,:K] = np.log(s**2)\n",
    "#         K_n.append(K)\n",
    "#         apogee_ids.append(key)\n",
    "        \n",
    "#         if n >= (N-1): \n",
    "#             break\n",
    "            \n",
    "#         elif n % 1000 == 0:\n",
    "#             print(n)    \n",
    "\n",
    "# K_n = np.array(K_n)\n",
    "# apogee_ids = np.array(apogee_ids)\n",
    "\n",
    "# # for nulling out the probability for non-existing samples\n",
    "# mask = np.zeros_like(y_nk)\n",
    "# mask[y_nk == 9999.] = -np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-compute value of the interim prior at the position of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_p0 = ln_normal(y_nk, float(run.jitter_mean), float(run.jitter_stddev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the posterior samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-8, 20, 32)\n",
    "plt.hist(np.ravel(y_nk)[np.isfinite(np.ravel(y_nk))], bins=bins, normed=True, alpha=0.6, label='all samples');\n",
    "plt.hist(np.nanmedian(y_nk, axis=1), bins=bins, normed=True, alpha=0.6, label='median over $k$');\n",
    "plt.legend(loc='upper left', fontsize=16)\n",
    "plt.xlabel(r'$y = \\ln s^2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teff = [s.teff for s in stars]\n",
    "logg = [s.logg for s in stars]\n",
    "snr = [s.snr for s in stars]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7,7.5), sharex='col', sharey='row')\n",
    "\n",
    "style = dict(c=np.nanmax(y_nk, axis=1), marker='o', s=8, alpha=0.65,\n",
    "             vmin=2, vmax=13, linewidth=0)\n",
    "c = axes[0,0].scatter(teff, snr, **style)\n",
    "axes[1,0].scatter(teff, logg, **style)\n",
    "axes[1,1].scatter(snr, logg, **style)\n",
    "\n",
    "axes[0,0].set_xlim(6000, 3500)\n",
    "axes[0,0].set_yscale('log')\n",
    "axes[1,1].set_xscale('log')\n",
    "axes[1,0].set_ylim(4, 0)\n",
    "\n",
    "axes[0,0].set_ylabel('SNR')\n",
    "axes[1,0].set_xlabel('Teff')\n",
    "axes[1,0].set_ylabel('log$g$')\n",
    "axes[1,1].set_xlabel('SNR')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[0,1].set_visible(False)\n",
    "\n",
    "fig.subplots_adjust(left=0.1, right=0.95, top=0.9)\n",
    "\n",
    "cax = fig.add_axes([0.1, 0.92, 0.85, 0.025])\n",
    "cb = fig.colorbar(c, cax=cax, orientation='horizontal')\n",
    "cb.set_label(r'${\\rm med}_k\\left(y_{nk}\\right)$', labelpad=10)\n",
    "cb.ax.xaxis.tick_top()\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "cb.set_clim(style['vmin'], style['vmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6,5))\n",
    "\n",
    "style = dict(marker='o', s=8, alpha=0.25, linewidth=0)\n",
    "c = ax.scatter(snr, np.nanmax(y_nk, axis=1), **style)\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylim(2, 15)\n",
    "\n",
    "ax.set_xlabel('SNR')\n",
    "ax.set_ylabel(r'${\\rm med}_k\\left(y_{nk}\\right)$')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The star with the largest value of the smallest $y$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = []\n",
    "# need the loop because some stars have less than 128 samples\n",
    "for i, K in zip(range(y_nk.shape[0]), K_n):\n",
    "    minmax.append(y_nk[i,:K].min())\n",
    "i = np.argmax(minmax)\n",
    "\n",
    "print(y_nk[i, :K_n[i]].min(), '{0:.2f} m/s'.format(np.sqrt(np.exp(y_nk[i, :K_n[i]].min()))), apogee_ids[i])\n",
    "print(i)\n",
    "\n",
    "star = session.query(AllStar).filter(AllStar.apogee_id == apogee_ids[i]).limit(1).one()\n",
    "data = star.apogeervdata(clean=True)\n",
    "\n",
    "samples = JokerSamples(trend_cls=VelocityTrend1, **load_samples(samples_file, apogee_ids[i]))\n",
    "_ = plot_data_orbits(data, samples)\n",
    "\n",
    "# residuals?\n",
    "for j in range(len(samples)):\n",
    "    this_samples = samples[j]\n",
    "    \n",
    "    trend_samples = dict()\n",
    "    for k in samples.trend_cls.parameters:\n",
    "        trend_samples[k] = this_samples.pop(k)\n",
    "    trend = samples.trend_cls(**trend_samples)\n",
    "    orbit = RVOrbit(trend=trend, **this_samples)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.errorbar(data.t.mjd, (data.rv - orbit.generate_rv_curve(data.t)).to(u.km/u.s).value, \n",
    "                data.stddev.to(u.km/u.s).value,\n",
    "                linestyle='none', marker='o')\n",
    "    ax.set_ylabel('residuals [{0:latex_inline}]'.format(u.km/u.s))\n",
    "    ax.set_xlabel('BMJD')\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The star with the smallest value of the largest $y$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = []\n",
    "# need the loop because some stars have less than 128 samples\n",
    "for i, K in zip(range(y_nk.shape[0]), K_n):\n",
    "    minmax.append(y_nk[i,:K].max())\n",
    "i = np.argmin(minmax)\n",
    "\n",
    "print(y_nk[i, :K_n[i]].min(), '{0:.2f} m/s'.format(np.sqrt(np.exp(y_nk[i, :K_n[i]].min()))), apogee_ids[i])\n",
    "print(i)\n",
    "\n",
    "star = session.query(AllStar).filter(AllStar.apogee_id == apogee_ids[i]).limit(1).one()\n",
    "data = star.apogeervdata()\n",
    "\n",
    "samples = JokerSamples(trend_cls=VelocityTrend1, **load_samples(samples_file, apogee_ids[i]))\n",
    "_ = plot_data_orbits(data, samples)\n",
    "\n",
    "# residuals?\n",
    "for j in range(len(samples)):\n",
    "    this_samples = samples[j]\n",
    "    \n",
    "    trend_samples = dict()\n",
    "    for k in samples.trend_cls.parameters:\n",
    "        trend_samples[k] = this_samples.pop(k)\n",
    "    trend = samples.trend_cls(**trend_samples)\n",
    "    orbit = RVOrbit(trend=trend, **this_samples)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.errorbar(data.t.mjd, (data.rv - orbit.generate_rv_curve(data.t)).to(u.km/u.s).value, \n",
    "                data.stddev.to(u.km/u.s).value,\n",
    "                linestyle='none', marker='o')\n",
    "    ax.set_ylabel('residuals [{0:latex_inline}]'.format(u.km/u.s))\n",
    "    ax.set_xlabel('BMJD')\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical inference of jitter parameter distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_likelihood_slow(pars, y, K, ln_prior0):\n",
    "    mu, std = pars   \n",
    "    \n",
    "    ll = np.zeros(y.shape[0])\n",
    "    for n in range(y.shape[0]):\n",
    "        delta_ln_prior = ln_normal(y[n, :K[n]], mu, std) - ln_prior0[n, :K[n]]\n",
    "        ll[n] = logsumexp(delta_ln_prior) - np.log(K[n])\n",
    "        \n",
    "    return ll\n",
    "\n",
    "def ln_likelihood(pars, y, K, ln_prior0):\n",
    "    \"\"\" Original, single Gaussian implementation \"\"\"\n",
    "    mu, std = pars      \n",
    "    delta_ln_prior = ln_normal(y, mu, std) - ln_prior0\n",
    "    delta_ln_prior[np.isnan(delta_ln_prior)] = -np.inf\n",
    "    ll = logsumexp(delta_ln_prior, axis=1) - np.log(K)\n",
    "    return ll\n",
    "\n",
    "def ln_prob(pars, y, K, ln_prior0):\n",
    "    # TODO: prior over mu, std of jitter param distribution\n",
    "    lp = 0.\n",
    "    \n",
    "    ll_n = ln_likelihood(pars, y, K, ln_prior0)\n",
    "    \n",
    "    if not np.all(np.isfinite(ll_n)):\n",
    "        return -np.inf\n",
    "    \n",
    "    return np.sum(ll_n)\n",
    "\n",
    "# check that the null masking is working\n",
    "test_pars = [np.random.uniform(-5, 5),\n",
    "             np.random.uniform(1E-3, 5)]\n",
    "\n",
    "assert np.allclose(ln_likelihood_slow(test_pars, y_nk, K_n, ln_p0),\n",
    "                   ln_likelihood(test_pars, y_nk, K_n, ln_p0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slc = (slice(0,3),) # single\n",
    "# slc = np.array([512,777])# + list(range(100))) # the two minmax stars above\n",
    "slc = (slice(None),) # all\n",
    "# slc = np.array([225, 139])\n",
    "args = (y_nk[slc], K_n[slc], ln_p0[slc])\n",
    "\n",
    "(ln_likelihood([-2, 4.], *args),\n",
    " ln_likelihood([2, 4.], *args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-5, 18, 55)\n",
    "\n",
    "_n_sub = y_nk[slc].shape[0]\n",
    "for _n in range(min(_n_sub, 8)):\n",
    "    plt.hist(y_nk[slc][_n][np.isfinite(y_nk[slc][_n])], bins=bins, \n",
    "             alpha=0.5, label='star {0}'.format(_n))\n",
    "\n",
    "plt.legend(loc='best')\n",
    "    \n",
    "vals = np.linspace(bins.min(), bins.max(), 1000)\n",
    "# lls = ln_normal_mixture(vals, [0.2, 0.8], [0, 1.], [6., 2.])\n",
    "# plt.plot(vals, np.exp(lls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(y_nk[slc].ravel()[y_nk[slc].ravel() < 9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-component likelihood\n",
    "sigma_y = 2.\n",
    "# sigma_y = np.std(y_nk[slc].ravel())\n",
    "\n",
    "lls = []\n",
    "vals = np.linspace(-5, 15, 128)\n",
    "for val in vals:\n",
    "    lls.append(ln_likelihood([val, sigma_y], *args).sum())\n",
    "    \n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,5), sharex=True)\n",
    "\n",
    "axes[0].plot(vals, lls)\n",
    "axes[0].set_ylabel(r'$\\ln p(\\{D_n\\}|\\alpha)$')\n",
    "axes[1].plot(vals, np.exp(lls - np.max(lls)))\n",
    "axes[1].set_ylabel(r'$p(\\{D_n\\}|\\alpha)$')\n",
    "\n",
    "# axes[1].axvline(np.mean(y_nk[slc].ravel()))\n",
    "\n",
    "axes[0].set_xlabel(r'$\\mu_y$')\n",
    "axes[1].set_xlabel(r'$\\mu_y$')\n",
    "\n",
    "axes[0].xaxis.set_ticks(np.arange(vals.min(), vals.max()+1, 2))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_grid = np.linspace(-10, 10, 27)\n",
    "# var_grid = np.linspace(0.1, 10, 25)**2\n",
    "std_grid = np.logspace(-3, 1.5, 25)\n",
    "mu_grid, std_grid = np.meshgrid(mu_grid, std_grid)\n",
    "\n",
    "probs = np.array([ln_prob([m, v], *args) \n",
    "                  for (m, v) in zip(mu_grid.ravel(), std_grid.ravel())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.min(), probs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_grid.ravel()[probs.argmax()], std_grid.ravel()[probs.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "\n",
    "plt.pcolormesh(mu_grid, std_grid,\n",
    "               probs.reshape(mu_grid.shape),\n",
    "               cmap='Blues', vmin=-1000, vmax=probs.max())\n",
    "# plt.pcolormesh(mu_grid, std_grid,\n",
    "#                np.exp(probs.reshape(mu_grid.shape)),\n",
    "#                cmap='Blues')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.colorbar()\n",
    "plt.xlabel(r'$\\mu_y$')\n",
    "plt.ylabel(r'$\\sigma_y$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwalkers = 16\n",
    "p0 = np.random.normal([5, 4.], [1E-3, 1E-3], size=(nwalkers, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, dim=2, lnpostfn=ln_prob,\n",
    "                                args=(y_nk, K_n, ln_p0))\n",
    "pos,*_ = sampler.run_mcmc(p0, 256)\n",
    "# sampler.reset()\n",
    "# _ = sampler.run_mcmc(pos, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.chain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in range(sampler.dim):\n",
    "    plt.figure()\n",
    "    for walker in sampler.chain[...,dim]:\n",
    "        plt.plot(walker, marker='', linestyle='-', color='k', \n",
    "                 alpha=0.2, drawstyle='steps-mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:twoface]",
   "language": "python",
   "name": "conda-env-twoface-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}