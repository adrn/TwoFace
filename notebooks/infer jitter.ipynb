{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.constants import G\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('apw-notebook')\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "from sqlalchemy import func\n",
    "from scipy.optimize import root\n",
    "\n",
    "from twoface.config import TWOFACE_CACHE_PATH\n",
    "from twoface.db import (db_connect, AllStar, AllVisit, AllVisitToAllStar, RedClump,\n",
    "                        StarResult, Status, JokerRun, initialize_db)\n",
    "\n",
    "from thejoker import JokerParams, TheJoker, JokerSamples\n",
    "from twoface.sample_prior import make_prior_cache\n",
    "from twoface.io import load_samples\n",
    "from twoface.plot import plot_data_orbits\n",
    "from twobody.celestial import RVOrbit, VelocityTrend1\n",
    "\n",
    "from scipy.misc import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('../cache/apogee-jitter.hdf5') as f:\n",
    "    print(len(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TWOFACE_CACHE_PATH = path.abspath('../cache/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Session, _ = db_connect(path.join(TWOFACE_CACHE_PATH, 'apogee.sqlite'))\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the run parameters:\n",
    "run = session.query(JokerRun).filter(JokerRun.name == 'apogee-jitter').one()\n",
    "\n",
    "# load the posterior samples:\n",
    "samples_file = path.join(TWOFACE_CACHE_PATH, '{0}.hdf5'.format(run.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ln_normal(x, mu, std):\n",
    "    return -0.5*( ((x-mu) / std)**2 + np.log(2*np.pi*std**2))\n",
    "\n",
    "def ln_normal_mixture(x, amp, mu, std):\n",
    "    n_components = len(amp)\n",
    "    \n",
    "    lls = []\n",
    "    for j in range(n_components):\n",
    "        lls.append(ln_normal(x, mu[j], std[j]) + np.log(amp[j]))\n",
    "    \n",
    "    return logsumexp(lls, axis=0)\n",
    "\n",
    "# test against (slower) scipy implementation:\n",
    "from scipy.stats import norm\n",
    "derp = np.random.uniform(-2, 2, size=100)\n",
    "pars = np.random.uniform(1E-3, 10, size=2)\n",
    "assert np.allclose(norm.logpdf(derp, loc=pars[0], scale=pars[1]),\n",
    "                   ln_normal(derp, *pars))\n",
    "\n",
    "assert np.allclose(ln_normal_mixture(derp, [1.], [pars[0]], [pars[1]]),\n",
    "                   ln_normal(derp, *pars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 1024)\n",
    "\n",
    "plt.plot(x, np.exp(ln_normal_mixture(x, [0.2, 0.8], [-4, 4], [0.5, 1])), \n",
    "         marker='')\n",
    "plt.axvline(-4)\n",
    "plt.axvline(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data by getting particular stars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The aspcapflag bitmask removes STAR_WARN\n",
    "# The starflag bitmask removes SUSPECT_BROAD_LINES \n",
    "# The logg cut remove TRGB stars - too much intrinsic jitter\n",
    "stars = session.query(AllStar).join(StarResult, JokerRun, Status, AllVisitToAllStar, AllVisit)\\\n",
    "                              .filter(Status.id > 0)\\\n",
    "                              .filter(JokerRun.name == 'apogee-jitter')\\\n",
    "                              .filter(AllStar.aspcapflag.op('&')(2**7) == 0)\\\n",
    "                              .filter(AllStar.starflag.op('&')(2**17) == 0)\\\n",
    "                              .filter(AllStar.logg > 2)\\\n",
    "                              .group_by(AllStar.apstar_id)\\\n",
    "                              .having(func.count(AllVisit.id) >= 15)\\\n",
    "                              .all()\n",
    "#                              .limit(1024).all()\n",
    "print(len(stars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_n = []\n",
    "apogee_ids = []\n",
    "with h5py.File(samples_file) as f:\n",
    "    # Values that aren't filled get set to nan\n",
    "    N = len(stars)\n",
    "    y_nk = np.full((N, 128), np.nan)\n",
    "    \n",
    "    for n, key in enumerate([s.apogee_id for s in stars]):\n",
    "        K = len(f[key]['jitter'])\n",
    "        \n",
    "        s = f[key]['jitter'][:] * 1000. # km/s to m/s\n",
    "        y_nk[n,:K] = np.log(s**2)\n",
    "        K_n.append(K)\n",
    "        apogee_ids.append(key)\n",
    "\n",
    "K_n = np.array(K_n)\n",
    "apogee_ids = np.array(apogee_ids)\n",
    "\n",
    "# for nulling out the probability for non-existing samples\n",
    "mask = np.zeros_like(y_nk)\n",
    "mask[y_nk == 9999.] = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(K_n)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('$K_n$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for apogee_id in apogee_ids[(K_n < 10)][:20]:\n",
    "# for apogee_id in apogee_ids[(K_n > 10) & (K_n < 100)][:20]:\n",
    "# for apogee_id in apogee_ids[(K_n > 100) & (K_n > 10)][:20]:\n",
    "    star = session.query(AllStar).filter(AllStar.apogee_id == apogee_id).limit(1).one()\n",
    "    data = star.apogeervdata(clean=True)\n",
    "\n",
    "    samples = JokerSamples(trend_cls=VelocityTrend1, **load_samples(samples_file, apogee_id))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 10), sharex=True)\n",
    "    \n",
    "    fig = plot_data_orbits(data, samples, ax=axes[0])\n",
    "    axes[0].set_title(r'$s_{{\\rm max}} = ${0:.3f}'.format(samples['jitter'].max().to(u.m/u.s)), \n",
    "                      fontsize=18)\n",
    "    \n",
    "    # residuals\n",
    "    ax = axes[1]\n",
    "    for label, j in zip(['max($P$)', 'min($P$)'], [samples['P'].argmax(), samples['P'].argmin()]):\n",
    "        this_samples = samples[j]\n",
    "\n",
    "        trend_samples = dict()\n",
    "        for k in samples.trend_cls.parameters:\n",
    "            trend_samples[k] = this_samples.pop(k)\n",
    "        trend = samples.trend_cls(**trend_samples)\n",
    "        orbit = RVOrbit(trend=trend, **this_samples)\n",
    "\n",
    "        ax.errorbar(data.t.mjd, (data.rv - orbit.generate_rv_curve(data.t)).to(u.km/u.s).value, \n",
    "                    data.stddev.to(u.km/u.s).value,\n",
    "                    linestyle='none', marker='o', label=label)\n",
    "        \n",
    "    ax.set_ylabel('residuals [{0:latex_inline}]'.format(u.km/u.s))\n",
    "    ax.set_xlabel('BMJD')\n",
    "    ax.axhline(0.)\n",
    "    ax.legend(loc='best', fontsize=16)\n",
    "    \n",
    "    fig.savefig(\"../plots/1-nsamples <10/{0}.png\".format(apogee_id), dpi=200)\n",
    "    # fig.savefig(\"../plots/2-nsamples 10\u2013100/{0}.png\".format(apogee_id), dpi=200)\n",
    "    # fig.savefig(\"../plots/3-nsamples >100/{0}.png\".format(apogee_id), dpi=200)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data by getting a random batch of some size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K_n = []\n",
    "# apogee_ids = []\n",
    "# with h5py.File(samples_file) as f:\n",
    "#     # Only load 10000 stars for now\n",
    "#     N = 2000\n",
    "#     # N = len(f.keys())\n",
    "    \n",
    "#     # Values that aren't filled get set to nan\n",
    "#     y_nk = np.full((N, 128), np.nan)\n",
    "    \n",
    "#     for n,key in enumerate(f):\n",
    "#         K = len(f[key]['jitter'])\n",
    "        \n",
    "#         s = f[key]['jitter'][:] * 1000. # km/s to m/s\n",
    "#         y_nk[n,:K] = np.log(s**2)\n",
    "#         K_n.append(K)\n",
    "#         apogee_ids.append(key)\n",
    "        \n",
    "#         if n >= (N-1): \n",
    "#             break\n",
    "            \n",
    "#         elif n % 1000 == 0:\n",
    "#             print(n)    \n",
    "\n",
    "# K_n = np.array(K_n)\n",
    "# apogee_ids = np.array(apogee_ids)\n",
    "\n",
    "# # for nulling out the probability for non-existing samples\n",
    "# mask = np.zeros_like(y_nk)\n",
    "# mask[y_nk == 9999.] = -np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-compute value of the interim prior at the position of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ln_p0 = ln_normal(y_nk, float(run.jitter_mean), float(run.jitter_stddev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the posterior samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-8, 20, 32)\n",
    "plt.hist(np.ravel(y_nk)[np.isfinite(np.ravel(y_nk))], bins=bins, normed=True, alpha=0.6, label='all samples');\n",
    "plt.hist(np.nanmedian(y_nk, axis=1), bins=bins, normed=True, alpha=0.6, label='median over $k$');\n",
    "plt.legend(loc='upper left', fontsize=16)\n",
    "plt.xlabel(r'$y = \\ln s^2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teff = [s.teff for s in stars]\n",
    "logg = [s.logg for s in stars]\n",
    "snr = [s.snr for s in stars]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7,7.5), sharex='col', sharey='row')\n",
    "\n",
    "style = dict(c=np.nanmax(y_nk, axis=1), marker='o', s=8, alpha=0.65,\n",
    "             vmin=2, vmax=13, linewidth=0)\n",
    "c = axes[0,0].scatter(teff, snr, **style)\n",
    "axes[1,0].scatter(teff, logg, **style)\n",
    "axes[1,1].scatter(snr, logg, **style)\n",
    "\n",
    "axes[0,0].set_xlim(6000, 3500)\n",
    "axes[0,0].set_yscale('log')\n",
    "axes[1,1].set_xscale('log')\n",
    "axes[1,0].set_ylim(4, 0)\n",
    "\n",
    "axes[0,0].set_ylabel('SNR')\n",
    "axes[1,0].set_xlabel('Teff')\n",
    "axes[1,0].set_ylabel('log$g$')\n",
    "axes[1,1].set_xlabel('SNR')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[0,1].set_visible(False)\n",
    "\n",
    "fig.subplots_adjust(left=0.1, right=0.95, top=0.9)\n",
    "\n",
    "cax = fig.add_axes([0.1, 0.92, 0.85, 0.025])\n",
    "cb = fig.colorbar(c, cax=cax, orientation='horizontal')\n",
    "cb.set_label(r'${\\rm med}_k\\left(y_{nk}\\right)$', labelpad=10)\n",
    "cb.ax.xaxis.tick_top()\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "cb.set_clim(style['vmin'], style['vmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6,5))\n",
    "\n",
    "style = dict(marker='o', s=8, alpha=0.25, linewidth=0)\n",
    "c = ax.scatter(snr, np.nanmax(y_nk, axis=1), **style)\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylim(2, 15)\n",
    "\n",
    "ax.set_xlabel('SNR')\n",
    "ax.set_ylabel(r'${\\rm med}_k\\left(y_{nk}\\right)$')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The star with the largest value of the smallest $y$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = []\n",
    "# need the loop because some stars have less than 128 samples\n",
    "for i, K in zip(range(y_nk.shape[0]), K_n):\n",
    "    minmax.append(y_nk[i,:K].min())\n",
    "i = np.argmax(minmax)\n",
    "\n",
    "print(y_nk[i, :K_n[i]].min(), '{0:.2f} m/s'.format(np.sqrt(np.exp(y_nk[i, :K_n[i]].min()))), apogee_ids[i])\n",
    "print(i)\n",
    "\n",
    "star = session.query(AllStar).filter(AllStar.apogee_id == apogee_ids[i]).limit(1).one()\n",
    "data = star.apogeervdata(clean=True)\n",
    "\n",
    "samples = JokerSamples(trend_cls=VelocityTrend1, **load_samples(samples_file, apogee_ids[i]))\n",
    "_ = plot_data_orbits(data, samples)\n",
    "\n",
    "# residuals?\n",
    "for j in range(len(samples)):\n",
    "    this_samples = samples[j]\n",
    "    \n",
    "    trend_samples = dict()\n",
    "    for k in samples.trend_cls.parameters:\n",
    "        trend_samples[k] = this_samples.pop(k)\n",
    "    trend = samples.trend_cls(**trend_samples)\n",
    "    orbit = RVOrbit(trend=trend, **this_samples)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.errorbar(data.t.mjd, (data.rv - orbit.generate_rv_curve(data.t)).to(u.km/u.s).value, \n",
    "                data.stddev.to(u.km/u.s).value,\n",
    "                linestyle='none', marker='o')\n",
    "    ax.set_ylabel('residuals [{0:latex_inline}]'.format(u.km/u.s))\n",
    "    ax.set_xlabel('BMJD')\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The star with the smallest value of the largest $y$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = []\n",
    "# need the loop because some stars have less than 128 samples\n",
    "for i, K in zip(range(y_nk.shape[0]), K_n):\n",
    "    minmax.append(y_nk[i,:K].max())\n",
    "i = np.argmin(minmax)\n",
    "\n",
    "print(y_nk[i, :K_n[i]].min(), '{0:.2f} m/s'.format(np.sqrt(np.exp(y_nk[i, :K_n[i]].min()))), apogee_ids[i])\n",
    "print(i)\n",
    "\n",
    "star = session.query(AllStar).filter(AllStar.apogee_id == apogee_ids[i]).limit(1).one()\n",
    "data = star.apogeervdata(clean=True)\n",
    "\n",
    "samples = JokerSamples(trend_cls=VelocityTrend1, **load_samples(samples_file, apogee_ids[i]))\n",
    "_ = plot_data_orbits(data, samples)\n",
    "\n",
    "# residuals?\n",
    "for j in range(len(samples)):\n",
    "    this_samples = samples[j]\n",
    "    \n",
    "    trend_samples = dict()\n",
    "    for k in samples.trend_cls.parameters:\n",
    "        trend_samples[k] = this_samples.pop(k)\n",
    "    trend = samples.trend_cls(**trend_samples)\n",
    "    orbit = RVOrbit(trend=trend, **this_samples)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.errorbar(data.t.mjd, (data.rv - orbit.generate_rv_curve(data.t)).to(u.km/u.s).value, \n",
    "                data.stddev.to(u.km/u.s).value,\n",
    "                linestyle='none', marker='o')\n",
    "    ax.set_ylabel('residuals [{0:latex_inline}]'.format(u.km/u.s))\n",
    "    ax.set_xlabel('BMJD')\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical inference of jitter parameter distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random(size=1000)\n",
    "%timeit ln_normal_mixture(x, [0.2, 0.8], [1, 10], [1, 5])\n",
    "%timeit ln_normal(x, 0.2, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self, y_nk, K_n, ln_p0, n_components=1):\n",
    "        self.y = y_nk\n",
    "        self.K = K_n\n",
    "        self.ln_p0 = ln_p0\n",
    "        self.n_components = int(n_components)\n",
    "        \n",
    "        self.ln_norm_func = ln_normal\n",
    "        if self.n_components > 1:\n",
    "            self.ln_norm_func = ln_normal_mixture\n",
    "\n",
    "    def ln_likelihood(self, **kwargs):\n",
    "        \"\"\" Original, single Gaussian implementation \"\"\"\n",
    "        delta_ln_prior = self.ln_norm_func(self.y, **kwargs) - self.ln_p0\n",
    "        delta_ln_prior[np.isnan(delta_ln_prior)] = -np.inf\n",
    "        return logsumexp(delta_ln_prior, axis=1) - np.log(self.K)\n",
    "    \n",
    "    def ln_prior(self, **kwargs):\n",
    "        lp = 0.\n",
    "        \n",
    "        amp = kwargs.get('amp', None)\n",
    "        if amp is not None:\n",
    "            amp = np.array(amp)\n",
    "            if amp.sum() > 1:\n",
    "                return -np.inf\n",
    "            \n",
    "            if np.any(amp < 0):\n",
    "                return -np.inf\n",
    "        \n",
    "        # enforce ordering of the means\n",
    "        if not np.allclose(np.argsort(kwargs['mu']), np.arange(self.n_components)):\n",
    "            return -np.inf\n",
    "        \n",
    "        # 1/sigma prior\n",
    "        lp += -np.sum(np.log(kwargs['std'])) \n",
    "        \n",
    "        return lp\n",
    "    \n",
    "    def unpack_pars(self, pars):\n",
    "        # TODO:\n",
    "        if self.n_components == 1:\n",
    "            mu, std = pars\n",
    "            return dict(mu=mu, std=std)\n",
    "            \n",
    "        else:\n",
    "            amp = np.concatenate((pars[:self.n_components-1], [1-sum(pars[:self.n_components-1])]))\n",
    "            mu = pars[self.n_components-1:2*self.n_components-1]\n",
    "            std = pars[2*self.n_components-1:]\n",
    "            return dict(amp=amp, mu=mu, std=std)\n",
    "    \n",
    "    def pack_pars(self, mu, std, amp=None):\n",
    "        pass\n",
    "\n",
    "    def ln_prob(self, pars_vec):\n",
    "        pars_kw = self.unpack_pars(pars_vec)\n",
    "        \n",
    "        lp = self.ln_prior(**pars_kw)\n",
    "        if not np.isfinite(lp):\n",
    "            return -np.inf\n",
    "\n",
    "        ll_n = self.ln_likelihood(**pars_kw)\n",
    "        if not np.all(np.isfinite(ll_n)):\n",
    "            return -np.inf\n",
    "\n",
    "        return np.sum(ll_n)\n",
    "    \n",
    "    def __call__(self, p):\n",
    "        return self.ln_prob(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slc = (slice(0,3),) # single\n",
    "# slc = np.array([512,777])# + list(range(100))) # the two minmax stars above\n",
    "slc = (slice(None),) # all\n",
    "# slc = np.array([225, 139])\n",
    "\n",
    "mm = Model(y_nk[slc], K_n[slc], ln_p0[slc], n_components=1)\n",
    "mm([-2, 4.]), mm([2, 4.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-5, 18, 55)\n",
    "\n",
    "_n_sub = y_nk[slc].shape[0]\n",
    "for _n in range(min(_n_sub, 8)):\n",
    "    plt.hist(y_nk[slc][_n][np.isfinite(y_nk[slc][_n])], bins=bins, \n",
    "             alpha=0.5, label='star {0}'.format(_n))\n",
    "\n",
    "plt.legend(loc='best')\n",
    "    \n",
    "vals = np.linspace(bins.min(), bins.max(), 1000)\n",
    "# lls = ln_normal_mixture(vals, [0.2, 0.8], [0, 1.], [6., 2.])\n",
    "# plt.plot(vals, np.exp(lls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = Model(y_nk[slc], K_n[slc], ln_p0[slc])\n",
    "\n",
    "# Single-component likelihood\n",
    "sigma_y = 2.\n",
    "# sigma_y = np.std(y_nk[slc].ravel())\n",
    "\n",
    "lls = []\n",
    "vals = np.linspace(-5, 15, 128)\n",
    "for val in vals:\n",
    "    lls.append(mm([val, sigma_y]).sum())\n",
    "    \n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,5), sharex=True)\n",
    "\n",
    "axes[0].plot(vals, lls)\n",
    "axes[0].set_ylabel(r'$\\ln p(\\{D_n\\}|\\alpha)$')\n",
    "axes[1].plot(vals, np.exp(lls - np.max(lls)))\n",
    "axes[1].set_ylabel(r'$p(\\{D_n\\}|\\alpha)$')\n",
    "\n",
    "# axes[1].axvline(np.mean(y_nk[slc].ravel()))\n",
    "\n",
    "axes[0].set_xlabel(r'$\\mu_y$')\n",
    "axes[1].set_xlabel(r'$\\mu_y$')\n",
    "\n",
    "axes[0].xaxis.set_ticks(np.arange(vals.min(), vals.max()+1, 2))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixture model\n",
    "mmix = Model(y_nk[slc], K_n[slc], ln_p0[slc], \n",
    "             n_components=2)\n",
    "\n",
    "lls = []\n",
    "vals = np.linspace(-5, 15, 128)\n",
    "for val in vals:\n",
    "    lls.append(mmix([0.8, val, 10, 2, 2]))\n",
    "    \n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,5), sharex=True)\n",
    "\n",
    "axes[0].plot(vals, lls)\n",
    "axes[0].set_ylabel(r'$\\ln p(\\{D_n\\}|\\alpha)$')\n",
    "axes[1].plot(vals, np.exp(lls - np.max(lls)))\n",
    "axes[1].set_ylabel(r'$p(\\{D_n\\}|\\alpha)$')\n",
    "\n",
    "# axes[1].axvline(np.mean(y_nk[slc].ravel()))\n",
    "\n",
    "axes[0].set_xlabel(r'$\\mu_y$')\n",
    "axes[1].set_xlabel(r'$\\mu_y$')\n",
    "\n",
    "axes[0].xaxis.set_ticks(np.arange(vals.min(), vals.max()+1, 2))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mmix = Model(y_nk[slc], K_n[slc], ln_p0[slc], \n",
    "             n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu_grid = np.linspace(-10, 20, 27)\n",
    "# var_grid = np.linspace(0.1, 10, 25)**2\n",
    "std_grid = np.logspace(-3, 1.5, 25)\n",
    "mu_grid, std_grid = np.meshgrid(mu_grid, std_grid)\n",
    "\n",
    "probs = np.array([mm([m, v]) \n",
    "                  for (m, v) in zip(mu_grid.ravel(), std_grid.ravel())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.min(), probs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_grid.ravel()[probs.argmax()], std_grid.ravel()[probs.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "\n",
    "plt.pcolormesh(mu_grid, std_grid,\n",
    "               probs.reshape(mu_grid.shape),\n",
    "               cmap='Blues', vmin=-1000, vmax=probs.max())\n",
    "# plt.pcolormesh(mu_grid, std_grid,\n",
    "#                np.exp(probs.reshape(mu_grid.shape)),\n",
    "#                cmap='Blues')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.colorbar()\n",
    "plt.xlabel(r'$\\mu_y$')\n",
    "plt.ylabel(r'$\\sigma_y$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mmix = Model(y_nk[slc], K_n[slc], ln_p0[slc], \n",
    "             n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p0 = [0.8, 7, 10, 2, 2]\n",
    "p0 = [10., 2]\n",
    "mmix(p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = minimize(lambda *args: -mmix(*args), x0=p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.linspace(-10, 20, 256)\n",
    "\n",
    "min_pars = mmix.unpack_pars(res.x)\n",
    "ll = mmix.ln_norm_func(y, **min_pars)\n",
    "\n",
    "fig,axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "axes[0].plot(y, np.exp(ll), marker='')\n",
    "axes[0].set_xlim(-10, 20)\n",
    "axes[0].set_xlabel(r'$y=\\ln\\left(\\frac{s}{1\\,{\\rm m}\\,{\\rm s}^{-1}} \\right)^2$')\n",
    "\n",
    "s = np.sqrt(np.exp(y))\n",
    "axes[1].plot(s, np.exp(ll) * 2/s, marker='')\n",
    "axes[1].set_xlim(-0.1, 400)\n",
    "axes[1].set_xlabel('jitter, $s$ [{0:latex_inline}]'.format(u.m/u.s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mmix = Model(y_nk[slc], K_n[slc], ln_p0[slc], \n",
    "             n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndim = 5\n",
    "nwalkers = 8*ndim\n",
    "p0 = np.random.normal([0.7, 7, 10, 2, 2], [1E-3]*ndim, size=(nwalkers, ndim))\n",
    "\n",
    "for pp in p0:\n",
    "    assert np.all(np.isfinite(mmix(pp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmix([0.8, 7, 10, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, dim=ndim, lnpostfn=mmix)\n",
    "pos,*_ = sampler.run_mcmc(p0, 1024)\n",
    "# sampler.reset()\n",
    "# _ = sampler.run_mcmc(pos, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler.chain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dim in range(sampler.dim):\n",
    "    plt.figure()\n",
    "    for walker in sampler.chain[...,dim]:\n",
    "        plt.plot(walker, marker='', linestyle='-', color='k', \n",
    "                 alpha=0.2, drawstyle='steps-mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = np.vstack((sampler.chain[:,500::8]))\n",
    "med_pars = mmix.unpack_pars(np.median(samples, axis=0))\n",
    "med_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.linspace(-10, 20, 256)\n",
    "\n",
    "ll = mmix.ln_norm_func(y, **med_pars)\n",
    "\n",
    "fig,axes = plt.subplots(1, 2, figsize=(12,5), sharey=True)\n",
    "\n",
    "axes[0].plot(y, np.exp(ll), marker='')\n",
    "axes[0].set_xlim(-10, 20)\n",
    "axes[0].set_xlabel(r'$y=\\ln\\left(\\frac{s}{1\\,{\\rm m}\\,{\\rm s}^{-1}} \\right)^2$')\n",
    "\n",
    "s = np.sqrt(np.exp(y))\n",
    "axes[1].plot(s, np.exp(ll) * 2/s, marker='')\n",
    "axes[1].set_xlim(-10, 500)\n",
    "axes[1].set_xlabel('jitter, $s$ [{0:latex_inline}]'.format(u.m/u.s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:twoface]",
   "language": "python",
   "name": "conda-env-twoface-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}